---
title: 'Overview'
---

OpenCopilot provides one coherent end-to-end stack which is purposely designed for building a variety of copilots.
From LLM selection (GPTs & OSS LLMs), knowledge base, monitoring, evaluation, etc - **out of the box it covers all the needs to build a useful copilot.**

<img className="block dark:hidden" src="/images/lightstack.png" />
<img className="hidden dark:block" src="/images/darkstack.png" />

### Application
* [Chat UI](/welcome/getting-started#4-chat-with-the-copilot) within the OpenCopilot Python package for quick development (JS SDK)
* [Front-end](https://github.com/opencopilotdev/opencopilot-frontend) template

### Orchestration
* Intuitive way to [define copilots in Python code](/welcome/getting-started)
* Support for adding [knowledge bases](/create/knowledge-base) to your copilot
    * Use external data sources, custom, or any LangChain-compatible document loader
* Manages conversation history for you
* [REST API](/integrate/rest-api), including streaming support
* Coming soon: dynamic context

### Iterative development
* [Evaluation](/create/evaluation) methods to measure improvements
* [Debugging](/create/debugging) tools to get detailed insight
* [Monitoring](/integrate/monitoring) for your LLM & copilot usage

### Models & infrastructure
* Use any LLM (`gpt-3.5-turbo-16k` by default)
* Easy to deploy on any infrastructure

## Design principles

OpenCopilot is designed with the following principles in mind:

* **Explicit is better than implicit**: copilot behavior should be defined explicitly, not hidden behind layers of abstractions and defaults.
* **Declarative Python**: instead of having tens of configuration files, a copilot should be defined in simple, readable, declarative Python.