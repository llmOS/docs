---
title: "Prompting"
---

![Prompt Meme](/images/prompt_meme.png)

Crafting a meta prompt effectively defines your copilot's role and behavior. This foundational step ensures the copilot responds according to your preferences.

## Crafting a Meta Prompt

**Iterate**! Your first attempt doesn't need to be perfect.

### Key Points:
1. Define the copilot's purpose and expected behavior. Browse [examples](https://github.com/opencopilotdev/opencopilot/blob/main/examples) for inspiration.
2. Familiarize with unique prompting techniques of each LLM, starting with OpenAI GPTs.
3. Begin by modifying an [example](https://github.com/opencopilotdev/opencopilot/blob/main/examples) prompt.
4. Begin simply, then refine to match your use case.
5. A lengthy prompt might hamper the LLM's performance.

### Example:

```text
You are an E-Commerce Copilot, an AI assistant for entrepeneurs selling products on their online shops.
You are having a conversation with a user who is an entrepeneur owning an online shop that sells running wear. 

=========
{context}
=========

{history}
User: {question}
E-Commerce Copilot answer in Markdown:
```

### Prompt Structure:

The prompt, dynamically filled during runtime, should contain:

- `{context}`: Relevant documents from your knowledge base.
- `{history}`: The conversation's history.
- `{question}`: The user's most recent query.

Do not modify or omit these variables.

## Refining the Meta Prompt

Improvement hinges on iteration and monitoring.

1. Chat with your copilot to judge its efficiency.
2. Refine by specifying its mission, response restrictions, reply sources, and specific response strategies.

```text
You are an E-Commerce Copilot, assisting online entrepreneurs.
You're conversing with an online running wear shop owner.
Aid them in enhancing business and revenue through advice. Always contextualize your answers.
If faced with vague queries like "How to make money?", seek specific details.

=========
{context}
=========

{history}
User: {question}
E-Commerce Copilot answer in Markdown:
```

Dive deeper into prompt engineering via [OpenAI's prompting guides](https://github.com/openai/openai-cookbook#prompting-guides). Always iterate: **modify -> interact -> refine**.

## Implementing the Meta Prompt

You can input the meta prompt as a `String` or from a `.txt` file in the copilot Python script.

### Direct String Implementation:

```python
from opencopilot import OpenCopilot

PROMPT = """
You are a Parrot Copilot. Your purpose is to repeat what the user says, but in a different wording.

=========
{context}
=========

{history}
User: {question}
Parrot Copilot answer in Markdown:
"""

copilot = OpenCopilot(
    openai_api_key="your-openai-api-key",
    llm="gpt-3.5-turbo-16k",
    prompt=PROMPT
    )

copilot()
```

### Using a `.txt` File:

Just reference the prompt text file using `prompt_file` during copilot initialization. Avoid using both `prompt` and `prompt_file`.

```python
copilot = OpenCopilot(
    openai_api_key="your-openai-api-key",
    llm="gpt-3.5-turbo-16k",
    prompt_file="my_prompt.txt"
    )
```

Modify the prompt or its source as needed, then execute `python copilot.py`.

The next step? Enhancing your copilot's knowledge base with custom data.
