---
title: "Prompting"
---

<img height="200" src="/images/prompt_meme.png" />

Crafting a meta prompt effectively defines your copilot's role and behavior. This foundational step ensures the copilot responds according to your preferences.

## Crafting a Meta Prompt

**Iterate**! Your first attempt doesn't need to be perfect.

### Key Points
1. Define the copilot's purpose and expected behavior. Browse [examples](https://github.com/opencopilotdev/opencopilot/blob/main/examples) for inspiration.
2. Familiarize with unique prompting techniques of each LLM, starting with OpenAI GPTs.
3. Begin by modifying an [example](https://github.com/opencopilotdev/opencopilot/blob/main/examples) prompt.
4. Begin simply, then refine to match your use case.
5. A lengthy prompt might hamper the LLM's performance.

### Example

```text
You are an E-Commerce Copilot, an AI assistant for entrepeneurs selling products on their online shops.
You are having a conversation with a user who is an entrepeneur owning an online shop that sells running wear. 

=========
{context}
=========

{history}
User: {question}
E-Commerce Copilot answer in Markdown:
```

### Prompt Structure

The prompt, dynamically filled during runtime, should contain:

- `{context}`: Relevant documents from your knowledge base.
- `{history}`: The conversation's history.
- `{question}`: The user's most recent query.

Do not modify or omit these variables.

## Refining the Meta Prompt

Improvement hinges on iteration and monitoring.

1. Chat with your copilot to judge its efficiency.
2. Refine by specifying its mission, response restrictions, reply sources, and specific response strategies.

```text
You are an E-Commerce Copilot, assisting online entrepreneurs.
You're conversing with an online running wear shop owner.
Aid them in enhancing business and revenue through advice. Always contextualize your answers.
If faced with vague queries like "How to make money?", seek specific details.

=========
{context}
=========

{history}
User: {question}
E-Commerce Copilot answer in Markdown:
```

Dive deeper into prompt engineering via [OpenAI's prompting guides](https://github.com/openai/openai-cookbook#prompting-guides). Always iterate: **modify -> interact -> refine**.

## Implementing the Meta Prompt

You can input the meta prompt as a `String` or from a `.txt` file in the copilot Python script.

### Direct String Implementation:

```python
from opencopilot import OpenCopilot

PROMPT = """
You are a Parrot Copilot. Your purpose is to repeat what the user says, but in a different wording.

=========
{context}
=========

{history}
User: {question}
Parrot Copilot answer in Markdown:
"""

copilot = OpenCopilot(
    openai_api_key="your-openai-api-key",
    llm="gpt-3.5-turbo-16k",
    prompt=PROMPT
    )

copilot()
```

### Using a `.txt` File

Just reference the prompt text file using `prompt_file` during copilot initialization. Avoid using both `prompt` and `prompt_file`.

```python
copilot = OpenCopilot(
    openai_api_key="your-openai-api-key",
    llm="gpt-3.5-turbo-16k",
    prompt_file="my_prompt.txt"
    )
```

Modify the prompt or its source as needed, then execute `python copilot.py`.

## Using the CLI to Generate Prompts

For those looking for a streamlined process to craft initial prompts, OpenCopilot provides a Command-Line Interface (CLI) tool. This tool auto-generates prompts based on a simple description you provide, making it a fantastic starting point.

### How to Use the CLI for Prompt Generation

To use the tool, follow the structure below:

```bash
opencopilot prompt [OPTIONS] DESCRIPTION
```

**Example:**

```bash
opencopilot prompt 'Copilot for teaching children mathematics'
```

The above command will generate a prompt tailored for teaching math to kids.

### Arguments

- `description`: This is the copilot's description. It's a mandatory argument that informs the nature of the prompt. For instance, "Copilot for teaching children mathematics."

### Options

- `--model`: This option lets you specify the model for which the prompt should be tailored. Available choices are `gpt` (default) and `llama2`.
  
  Example:
  
  ```bash
  opencopilot prompt 'Copilot for teaching children mathematics' --model llama2
  ```

- `--help`: Provides the help message detailing the command's usage.

Remember, while the CLI is a great way to kickstart your prompt creation, it's always beneficial to refine and iterate on the generated prompt to perfectly suit your use case.

The next step? Enhancing your copilot's knowledge base with custom data.